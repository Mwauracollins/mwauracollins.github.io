<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>GPT on mwaura.AI</title>
    <link>https://mwauracollins.github.io/tags/gpt/</link>
    <description>Recent content in GPT on mwaura.AI</description>
    <generator>Hugo -- 0.143.1</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Feb 2025 22:20:47 +0300</lastBuildDate>
    <atom:link href="https://mwauracollins.github.io/tags/gpt/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Rolling Your Own GPT</title>
      <link>https://mwauracollins.github.io/posts/2025-02-04-gpt/</link>
      <pubDate>Tue, 04 Feb 2025 22:20:47 +0300</pubDate>
      <guid>https://mwauracollins.github.io/posts/2025-02-04-gpt/</guid>
      <description>&lt;p&gt;Training a GPT model sounds like a moonshot but it is actually just a series of simple and well-defined steps.
At its core, it is just a giant text predictor, fed with tons of data and then allowed to guess the next word. The real challenge is not training it to predict the next word, but to make it produce something useful like answers to your assignment due midnight.ðŸ˜…
You need some special type of training like &lt;strong&gt;Reinforcement Learning with Human Feedback &lt;a href=&#34;#rlhf&#34;&gt;(RLHF)&lt;/a&gt;&lt;/strong&gt;. Though you can get good responses without RLHF, RLHF is required to make it chatbot-like.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
