<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Autoencoders | mwaura.AI</title>
<meta name=keywords content="autoencoders,deep-learning,generative-models"><meta name=description content="An overview of autoencoders with a simplified explanation."><meta name=author content="Mwaura Collins"><link rel=canonical href=https://mwauracollins.github.io/posts/2025-01-16-autoencoders/><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css rel=stylesheet><link rel=icon href=https://mwauracollins.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://mwauracollins.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mwauracollins.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://mwauracollins.github.io/apple-touch-icon.png><link rel=mask-icon href=https://mwauracollins.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://mwauracollins.github.io/posts/2025-01-16-autoencoders/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://mwauracollins.github.io/posts/2025-01-16-autoencoders/"><meta property="og:site_name" content="mwaura.AI"><meta property="og:title" content="Autoencoders"><meta property="og:description" content="An overview of autoencoders with a simplified explanation."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-15T21:23:02+03:00"><meta property="article:modified_time" content="2025-01-15T21:23:02+03:00"><meta property="article:tag" content="Autoencoders"><meta property="article:tag" content="Deep-Learning"><meta property="article:tag" content="Generative-Models"><meta name=twitter:card content="summary"><meta name=twitter:title content="Autoencoders"><meta name=twitter:description content="An overview of autoencoders with a simplified explanation."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://mwauracollins.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Autoencoders","item":"https://mwauracollins.github.io/posts/2025-01-16-autoencoders/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Autoencoders","name":"Autoencoders","description":"An overview of autoencoders with a simplified explanation.","keywords":["autoencoders","deep-learning","generative-models"],"articleBody":"What are autoencoders? An autoencoder is a neural network that reconstructs a high dimensional input through a compressed lower dimension bottleneck.\nThe idea for autoencoders is to take a high dimensional input, compress it to a lower dimension that represents the image’s features, and then reconstruct the image from the bottleneck. The autoencoder is essentially like a dimensionality reduction method like PCA (Principal Component Analysis)\nThe idea was originally from the 1980s and was later promoted by Hinton \u0026 Salakhutdinov, 2006[1]\nStructure of Autoencoders The autoencoder consists of two section:\nThe encoder - Takes the high dimensional input and compresses it to a latent low dimensional code which is a vector. The decoder - Tries to reconstruct the original input given the bottleneck. Explanation The model has the encoder function $g(.)$ which parameterized by $\\phi$ and the decoder function $f(.)$ parameterized by $\\theta$. The latent code $\\mathbf{z} = f_\\theta(.)$. Therefore, the reconstructed input is a function $\\mathbf{x'} = f_\\theta(g_\\phi(.))$. The aim is for the model to reconstruct the input such that $\\mathbf{x'}\\approx\\mathbf{x^{(i)} }$ These parameters are learnt together by the model to get the output. Now, to quantify the output of the model a simple loss MSE is used\n$$ Loss(\\phi, \\theta) = \\frac{1}{n} (\\mathbf{x^{(i)}} - \\mathbf{x'})^2 $$ Lets take an example of a dataset $D$ with datapoints {$\\mathbf{x^{1}}, \\mathbf{x^{2}}, ... \\mathbf{x^{i}}$} with mammals e.g. humans, whales and jaguar. We want to map the data distribution of the data points to a latent space $\\mathbf{z}$. Meaning: we are taking a data point (lets say human) and mapping it to a low dimension that explains all the humans in the dataset $D$. This is kinda like explaining all the humans through facial features, torso length e.t.c.\nThese features explaining the data points are points in the latent space.\nThe downside of this model is that the model just learns the identity function which puts us at a risk of overfitting. So to prevent this, a new model was proposed [2] which introduced an additional layer between the input and the encoder which would partially destroy the input by adding noise. This can be done through various methods like salt and pepper noise or gaussian noise. Now, the loss is calculated by using the original input $\\mathbf{x^{i}}$ rather than the corrupted one $\\tilde{\\mathbf{x}}$ Now updating the loss function, we get:\n$$ Loss(\\phi, \\theta) = \\frac{1}{n} (\\mathbf{x^{(i)}} - f_\\theta(g_\\phi(\\tilde{\\mathbf{x}})))^2 $$ Sparse Autoencoders A Sparse Autoencoder[3] (SAE) introduces a sparsity constraint on the hidden layer to enforce the model to learn meaningful features of the data. The sparsity constraint ensures that only a small number of neurons are “active” (have high activation values) for any given input, which promotes feature selection and boosts robustness.\nWhy Sparsity? The sparsity constraint makes the autoencoder focus on capturing essential features of the data, rather than just memorizing input-output mappings. This is especially useful when:\nThe input data has high dimensionality (e.g. images). We want to learn interpretable features. The dataset is noisy, and only certain features are relevant. Sparsity is typically enforced by adding a regularization term to the loss function. A common choice is the Kullback-Leibler (KL) divergence, which measures the difference between:\nThe average activation of a neuron $ \\hat{\\rho}_j $, and A target sparsity value $ \\rho$ (e.g., $\\rho = 0.05 $). $$ \\text{Sparsity Penalty} = \\sum_{j=1}^m \\text{KL}(\\rho || \\hat{\\rho}_j) $$$$ = \\sum_{j=1}^m [ \\rho \\log \\frac{\\rho}{\\hat{\\rho}_j} + (1 - \\rho) \\log \\frac{1 - \\rho}{1 - \\hat{\\rho}_j}] $$where:\n$\\hat{\\rho}_j$: The average activation of the $j$-th hidden neuron across the dataset. $m$: The number of hidden neurons. $$ L = L_\\text{reconstruction} + \\beta \\cdot \\text{Sparsity Penalty}, $$ where $\\beta$ is a hyperparameter controlling the importance of sparsity.\nK-Sparse Autoencoders A K-Sparse Autoencoder[4] is a specific type of sparse autoencoder where exactly $k$ neurons in the hidden layer are allowed to be “active” for any given input. This enforces a strict sparsity constraint, where only the top $k$ activations (largest values) are retained, and the rest are set to zero.\nHow K-Sparsity Works For each input $\\mathbf{x} $: Compute the activations of the hidden layer. Retain the top $k $ activations (by magnitude) and set all others to zero. During backpropagation, only the selected $k$ -active neurons contribute to the gradient update. This approach has the following properties:\nIt ensures a fixed level of sparsity ($k $-out-of-$ m $ neurons active). It does not require additional sparsity penalties in the loss function, as the sparsity is explicitly enforced. Variational Autoencoders One major limitation of standard autoencoders is that their latent space often lacks meaningful structure. When sampling random points from the latent space, the decoder may produce nonsensical or meaningless outputs. This happens because the decoder is not explicitly trained to map random points in the latent space back to realistic data.\nTo address this issue, the authors of the paper [5] take a different approach. Instead of learning fixed features for a data point, VAEs aim to learn the distribution of the dataset $D$, which we denote as $p_*(\\mathbf{x})$.\nFor the example before, with VAEs, when sampling random points from the latent space we get a morph of mammals i.e a point between human and jaguar will produce an image of the combined.\nExplanation The goal of the VAEs is to generate unseen data by learning a distribution $p_\\theta(\\mathbf{x})$ that approximates the true distribution $p_*(\\mathbf{x})$:\n$$ p_\\theta(\\mathbf{x}) \\approx p_*(\\mathbf{x}). $$To achieve this, we maximize the likelihood of the model’s distribution $p_\\theta(\\mathbf{x})$. Specifically, the objective is to find the parameters $ \\theta$ that maximize the likelihood of the observed data:\n$$ \\theta^* = \\arg\\max_\\theta \\prod_{i=1}^n p_\\theta(\\mathbf{x}^{(i)}). $$$$ \\theta^* = \\arg\\max_\\theta \\sum_{i=1}^n \\log p_\\theta(\\mathbf{x}^{(i)}). $$$$ p_\\theta(\\mathbf{x}) = \\int_\\mathbf{z} p_\\theta(\\mathbf{x} \\vert \\mathbf{z}) p_\\theta(\\mathbf{z}) d\\mathbf{z}. $$The Challenge: Intractability The problem with directly evaluating this integral is that it is computationally infeasible. Marginalizing over $\\mathbf{z}$ requires summing over all possible values of $\\mathbf{z}$, which is not practical due to the high dimensionality of the latent space.\nThe Solution: Variational Approximation To approximate this integral, VAEs introduce a variational distribution $q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) $ as a surrogate for the intractable posterior $ p_\\theta(\\mathbf{z} \\vert \\mathbf{x}) $. This approximation enables efficient optimization using the Evidence Lower Bound (ELBO), which we will explore in detail next.\nREM: Bayes Theorem $$ P(H|E) = \\frac{P(H) \\space P(E|H)} {P(E)} $$ where;\n$P(H|E)$ - The posterior probability. The probability of getting the hypothesis $H$ given we have observed an event $E$.\n$P(H)$ - The prior probability. The probability of getting the hypothesis without the evidence.\n$P(E|H)$ - The likelihood/ the update. The probability of observing an event given we have formulated a hypothesis.\n$P(E)$ - The marginal likelihood/model evidence. The probability of just observing the event without the hypothesis. Normalizer\nVariational Inference $$ p_\\theta(\\mathbf{z|x}) = \\frac{p_\\theta(\\mathbf{z}) \\space p_\\theta(\\mathbf{x|z})} {p_\\theta(\\mathbf{x})} $$ We would like to maximize $p_\\theta(\\mathbf{x})$(which is intractable) but since $p_\\theta(\\mathbf{x}) = \\frac{p_\\theta(\\mathbf{z,x})}{p_\\theta(\\mathbf{z|x})}$ getting $p_\\theta(\\mathbf{z|x})$ would also be computationally expensive as the probability depends on knowledge on $p_\\theta(\\mathbf{x})$\n$$ q_\\phi(\\mathbf{z|x}) \\approx p_\\theta(\\mathbf{z|x}) $$ where; $q_\\phi(\\mathbf{z|x})$ is the approximation and $p_\\theta(\\mathbf{z|x})$ is the target.\nFigure2: VAE showing the variational inference We minimize the gap between the two distributions by using the Kullback-Leibler Divergence\n$$ D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x})\\space || \\space p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) ) $$The above means; the information lost if we adopt the $p_\\phi(\\mathbf{z|x})$ as our true distribution and $p_\\theta(\\mathbf{z|x}) $ as the approximation.\n$$ \\begin{aligned} \u0026\\displaystyle D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) ) \u0026 \\\\ \u0026= \\int_z q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) \\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z} \\vert \\mathbf{x})} d\\mathbf{z} \u0026 \\\\ \u0026= \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}[\\log \\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z} \\vert \\mathbf{x})}] \u0026 \\\\ \u0026=\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} [\\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) - \\log p_\\theta(\\mathbf{z} \\vert \\mathbf{x})] \u0026 \\\\ \u0026=\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log p_\\theta(\\mathbf{z} \\vert \\mathbf{x}) \u0026 \\\\ \u0026=\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log [\\frac {p_\\theta(\\mathbf{z}, \\mathbf{x})}{p_\\theta(\\mathbf{x})}] \u0026 \\scriptstyle{\\text{; Because }p(z \\vert x) = p(z, x) / p(x)\\text{}} \\\\ \u0026=\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log p_\\theta(\\mathbf{z} , \\mathbf{x}) + \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log p_\\theta(\\mathbf{x}) \u0026 \\\\ \u0026=\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log p_\\theta(\\mathbf{z} , \\mathbf{x}) + \\int{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log p_\\theta(\\mathbf{x}) d\\mathbf{z} \u0026 \\\\ \u0026=\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log p_\\theta(\\mathbf{z} , \\mathbf{x}) + \\log p_\\theta(\\mathbf{x}) \u0026 \\scriptstyle {\\text{; Because }\\int q(z \\vert x) dz = 1} \\\\ \u0026=\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} [\\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) - \\log p_\\theta(\\mathbf{z} , \\mathbf{x})] + \\log p_\\theta(\\mathbf{x}) \u0026 \\\\ \u0026=\\log p_\\theta(\\mathbf{x}) + \\int_z q_\\phi(\\mathbf{z} \\vert \\mathbf{x})\\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z}, \\mathbf{x})} d\\mathbf{z} \u0026 \\\\ \u0026=\\log p_\\theta(\\mathbf{x}) + \\int_z q_\\phi(\\mathbf{z} \\vert \\mathbf{x})\\log\\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{x}\\vert\\mathbf{z})p_\\theta(\\mathbf{z})} d\\mathbf{z} \u0026\\scriptstyle{\\text{; Because }p(z, x) = p(x \\vert z) p(z)} \\\\ \u0026=\\log p_\\theta(\\mathbf{x}) + \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}[\\log \\frac{q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{p_\\theta(\\mathbf{z})} - \\log p_\\theta(\\mathbf{x} \\vert \\mathbf{z})] \u0026 \\\\ \u0026=\\log p_\\theta(\\mathbf{x}) + D_\\text{KL}(q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}\\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) \u0026 \\end{aligned} $$Another way to derive it is using the Jensen’s Inequality\nIf we rearrange the equation, we should get\n$$ \\log p_\\theta(\\mathbf{x}) - D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) ) = \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}\\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) - D_\\text{KL}(q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) $$On the LHS, we have the log likelihood which we would wish to maximize or to say minimize the negative log likelihood. The KL Divergence acts as a regularizer. Since the KL Divergence is always positive, the RHS is the lower bound of the $\\log p_\\theta(\\mathbf{x})$\n$$ \\text{ELBO} = -\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log\\frac { q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{ p_\\theta(\\mathbf{z} , \\mathbf{x})} $$$$ \\text{ELBO} = \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log\\frac { p_\\theta(\\mathbf{z} , \\mathbf{x})}{ q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} $$$$ \\text{ELBO} = \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})}\\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) - D_\\text{KL}(q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z})) $$The loss function is the negative log likelihood:\n$$ \\begin{aligned} \u0026L_(\\theta, \\phi) \\\\ \u0026=-\\log p_\\theta(\\mathbf{x}) + D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}\\vert\\mathbf{x}) ) \\\\ \u0026=-\\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x})} \\log p_\\theta(\\mathbf{x}\\vert\\mathbf{z}) + D_\\text{KL}( q_\\phi(\\mathbf{z}\\vert\\mathbf{x}) \\| p_\\theta(\\mathbf{z}) ) \\\\ \u0026\\theta^{*}, \\phi^{*} = \\arg\\min_{\\theta, \\phi} L \\end{aligned} $$$$ \\nabla_{\\theta,\\phi} {L} = \\nabla_\\theta [- \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log\\frac { q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{ p_\\theta(\\mathbf{z} , \\mathbf{x})}] $$ They solved this using the reparameterization trick.\nReparameterization Trick Lets try backproping from the loss w.r.t $\\theta$\n$$ L(\\theta, \\phi) = - \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log\\frac { q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{ p_\\theta(\\mathbf{z} , \\mathbf{x})} $$$$ \\begin{aligned} \u0026\\nabla_\\theta {L} = \\nabla_\\theta [- \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log\\frac { q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{ p_\\theta(\\mathbf{z} , \\mathbf{x})}] \\\\ \u0026= \\nabla_\\theta [\\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log\\frac { p_\\theta(\\mathbf{z} , \\mathbf{x})}{ q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}] \\\\ \u0026= \\nabla_\\theta(\\int_z q_\\phi(\\mathbf{z} \\vert \\mathbf{x})[\\log\\ p_\\theta(\\mathbf{z} , \\mathbf{x}) - \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x})]d\\mathbf{z}) \\\\ \u0026= \\int_z q_\\phi(\\mathbf{z} \\vert \\mathbf{x})\\nabla_\\theta[\\log\\ p_\\theta(\\mathbf{z} , \\mathbf{x}) - \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x})]d\\mathbf{z} \\\\ \u0026= \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\nabla_\\theta[\\log\\ p_\\theta(\\mathbf{z} , \\mathbf{x}) - \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x})] \\\\ \u0026= \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\nabla_\\theta[\\log\\ p_\\theta(\\mathbf{z} , \\mathbf{x}) ] \\end{aligned} $$We can see that the gradient of the expectation is just the expectation of the gradient. We can easily estimate the expectation using Naïve Monte-Carlo sampling.\n$$ \\nabla_\\theta {L} \\approx \\frac {1}{n} \\sum_{i=1} ^n \\nabla_\\theta[\\log\\ p_\\theta(\\mathbf{z} , \\mathbf{x}) ] $$The problem now is the gradient w.r.t $\\phi$\n$$ \\begin{aligned} \u0026\\nabla_\\phi {L} = \\nabla_\\phi [- \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}\\log\\frac { q_\\phi(\\mathbf{z} \\vert \\mathbf{x})}{ p_\\theta(\\mathbf{z} , \\mathbf{x})}] \\\\ \u0026= \\nabla_\\phi (\\int_z q_\\phi(\\mathbf{z} \\vert \\mathbf{x})[\\log\\ p_\\theta(\\mathbf{z} , \\mathbf{x}) - q_\\phi(\\mathbf{z} \\vert \\mathbf{x})]d\\mathbf{z}) \\\\ \u0026= \\int_z \\nabla_\\phi [q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) \\cdot\\text{ELBO}]d\\mathbf{z} \\\\ \u0026= \\int_z q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) \\cdot \\nabla_\\phi \\text{ELBO} d\\mathbf{z} + \\int_z \\text{ELBO} \\cdot \\nabla_\\phi q_\\phi(\\mathbf{z} \\vert \\mathbf{x})d\\mathbf{z} \\\\ \u0026= \\mathbb{E}_{\\mathbf{z}\\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} \\cdot \\nabla_\\phi \\text{ELBO} + \\int_z \\text{ELBO} \\cdot \\nabla_\\phi q_\\phi(\\mathbf{z} \\vert \\mathbf{x})d\\mathbf{z} \\end{aligned} $$You can notice that the first term can be estimated as it is an expectation. However, the second expression is not an expectation and therefore cannot be calculated because we do not have the gradient of $q_\\phi$. The solution is to replace $q$ with an equivalent distribution that is not parameterized by $\\phi$. This is the reparameterization trick.\n$$ \\begin{aligned} \\mathbf{z} \u0026\\sim q_\\phi(\\mathbf{z}\\vert\\mathbf{x}^{(i)}) = \\mathcal{N}(\\mathbf{z}; \\boldsymbol{\\mu}^{(i)}, \\boldsymbol{\\sigma}^{2(i)}\\boldsymbol{I}) \\\\ \\mathbf{z} \u0026= \\boldsymbol{\\mu} + \\boldsymbol{\\sigma} \\odot \\boldsymbol{\\epsilon} \\text{, where } \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, \\boldsymbol{I}) \\end{aligned} $$This essentially tranfers the randomness from $\\mathbf{z}$ to an external variable $\\boldsymbol{\\epsilon}$\nGradient w.r.t. $ \\phi$ with reparameterization. Using the reparameterization trick, we rewrite $\\mathbf{z}$ as:\n$$ \\mathbf{z} = \\boldsymbol{\\mu}_\\phi(\\mathbf{x}) + \\boldsymbol{\\sigma}_\\phi(\\mathbf{x}) \\odot \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I}). $$$$ \\text{ELBO}(\\phi, \\theta) = \\mathbb{E}_{\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\log \\frac{p_\\theta(\\mathbf{z}, \\mathbf{x})} {q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} $$The gradient w.r.t. $ \\phi$ is:\n$$ \\nabla_\\phi L = - \\nabla_\\phi \\mathbb{E}_{\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\log \\frac{p_\\theta(\\mathbf{z}, \\mathbf{x})} {q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} $$$$ \\nabla_\\phi L = - \\mathbb{E}_{\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})} \\left[ \\nabla_\\phi \\log p_\\theta(\\mathbf{z}, \\mathbf{x}) - \\nabla_\\phi \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) \\right]. $$Breaking Down the Gradients: Gradient of $\\log p_\\theta(\\mathbf{z}, \\mathbf{x}) $: Since $\\mathbf{z}$ depends on $\\phi $ through $\\boldsymbol{\\mu}_\\phi$ and $\\boldsymbol{\\sigma}_\\phi $, the gradient propagates as:\n$$ \\nabla_\\phi \\log p_\\theta(\\mathbf{z}, \\mathbf{x}) = \\nabla_\\mathbf{z} \\log p_\\theta(\\mathbf{z}, \\mathbf{x}) \\cdot \\nabla_\\phi \\mathbf{z}. $$ Gradient of $\\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x})$: For a Gaussian distribution $q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) = \\mathcal{N}(\\boldsymbol{\\mu}_\\phi, \\boldsymbol{\\sigma}_\\phi^2 \\mathbf{I})$, the log-probability is:\n$$ \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) = -\\frac{1}{2} \\left[ \\log (2\\pi) + \\log (\\boldsymbol{\\sigma}_\\phi^2) + \\frac{(\\mathbf{z} - \\boldsymbol{\\mu}_\\phi)^2}{\\boldsymbol{\\sigma}_\\phi^2} \\right]. $$Its gradient w.r.t. $\\phi$ is:\n$$ \\nabla_\\phi \\log q_\\phi(\\mathbf{z} \\vert \\mathbf{x}) = \\nabla_\\phi \\left( \\frac{\\mathbf{z} - \\boldsymbol{\\mu}_\\phi}{\\boldsymbol{\\sigma}_\\phi^2} \\cdot (\\mathbf{z} - \\boldsymbol{\\mu}_\\phi) - \\log \\boldsymbol{\\sigma}_\\phi \\right). $$ Gradient w.r.t. $\\theta$ As derived earlier, the gradient w.r.t. $\\theta$ is simpler:\n$$ \\nabla_\\theta L = \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z} \\vert \\mathbf{x})} \\nabla_\\theta \\log p_\\theta(\\mathbf{z}, \\mathbf{x}) $$Using Monte Carlo sampling, this is approximated as:\n$$ \\nabla_\\theta L \\approx \\frac{1}{n} \\sum_{i=1}^n \\nabla_\\theta \\log p_\\theta(\\mathbf{z}^{(i)}, \\mathbf{x}) $$ References Geoffrey E. Hinton, and Ruslan R. Salakhutdinov. Reducing the dimensionality of data with neural networks (2006). Pascal Vincent, et al. Extracting and composing robust features with denoising autoencoders (2008) Andrew Ng. Sparse Autoencoder Alireza Makhzani, Brendan Frey (2013). k-sparse autoencoder (2014). Diederik P. Kingma, and Max Welling. Auto-encoding variational bayes (2014). ","wordCount":"2265","inLanguage":"en","datePublished":"2025-01-15T21:23:02+03:00","dateModified":"2025-01-15T21:23:02+03:00","author":{"@type":"Person","name":"Mwaura Collins"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mwauracollins.github.io/posts/2025-01-16-autoencoders/"},"publisher":{"@type":"Organization","name":"mwaura.AI","logo":{"@type":"ImageObject","url":"https://mwauracollins.github.io/favicon.ico"}}}</script><script>MathJax={tex:{inlineMath:[["$","$"]],displayMath:[["$$","$$"]]}}</script><script defer src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mwauracollins.github.io/ accesskey=h title="mwaura.AI (Alt + H)">mwaura.AI</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mwauracollins.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://mwauracollins.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://mwaura.tech/ title=mwaura.tech><span>mwaura.tech</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://mwauracollins.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://mwauracollins.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Autoencoders</h1><div class=post-description>An overview of autoencoders with a simplified explanation.</div><div class=post-meta><span title='2025-01-15 21:23:02 +0300 EAT'>January 15, 2025</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;2265 words&nbsp;·&nbsp;Mwaura Collins</div></header><div class=post-content><h2 id=what-are-autoencoders>What are autoencoders?<a hidden class=anchor aria-hidden=true href=#what-are-autoencoders>#</a></h2><p>An autoencoder is a neural network that reconstructs a high dimensional input through a compressed lower dimension <strong>bottleneck</strong>.</p><p>The idea for autoencoders is to take a high dimensional input, compress it to a lower dimension that represents the image&rsquo;s features, and then reconstruct the image from the bottleneck. The autoencoder is essentially like a dimensionality reduction method like PCA (Principal Component Analysis)</p><p>The idea was originally from the 1980s and was later promoted by Hinton & Salakhutdinov, 2006<a href=https://pdfs.semanticscholar.org/c50d/ca78e97e335d362d6b991ae0e1448914e9a3.pdf>[1]</a></p><h3 id=structure-of-autoencoders>Structure of Autoencoders<a hidden class=anchor aria-hidden=true href=#structure-of-autoencoders>#</a></h3><p>The autoencoder consists of two section:</p><ul><li>The encoder - Takes the high dimensional input and compresses it to a latent low dimensional code which is a vector.</li><li>The decoder - Tries to reconstruct the original input given the bottleneck.</li></ul><p><img alt="Figure 1: The model architecture for an autoencoder" loading=lazy src=/images/autoencoder/autoencoder.png></p><h3 id=explanation>Explanation<a hidden class=anchor aria-hidden=true href=#explanation>#</a></h3><p>The model has the encoder function $g(.)$ which parameterized by $\phi$ and the decoder function $f(.)$ parameterized by $\theta$. The latent code $\mathbf{z} = f_\theta(.)$. Therefore, the reconstructed input is a function $\mathbf{x'} = f_\theta(g_\phi(.))$. The aim is for the model to reconstruct the input such that
$\mathbf{x'}\approx\mathbf{x^{(i)} }$
These parameters are learnt together by the model to get the output. Now, to quantify the output of the model a simple loss MSE is used</p>$$
Loss(\phi, \theta) = \frac{1}{n} (\mathbf{x^{(i)}} - \mathbf{x'})^2
$$<hr><p>Lets take an example of a dataset $D$ with datapoints {$\mathbf{x^{1}}, \mathbf{x^{2}}, ... \mathbf{x^{i}}$} with mammals e.g. humans, whales and jaguar. We want to map the data distribution of the data points to a latent space $\mathbf{z}$. Meaning: we are taking a data point (lets say human) and mapping it to a low dimension that explains all the humans in the dataset $D$. This is kinda like explaining all the humans through facial features, torso length e.t.c.</p><hr><p>These features explaining the data points are points in the latent space.</p><p><img alt="Figure 2: An illustration of the latent space for " loading=lazy src=/images/autoencoder/example-ae2.png></p><p>The downside of this model is that the model just learns the identity function which puts us at a risk of overfitting. So to prevent this, a new model was proposed <a href=http://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf>[2]</a> which introduced an additional layer between the input and the encoder which would partially destroy the input by adding noise. This can be done through various methods like salt and pepper noise or gaussian noise.
Now, the loss is calculated by using the original input $\mathbf{x^{i}}$ rather than the corrupted one $\tilde{\mathbf{x}}$
Now updating the loss function, we get:</p>$$
Loss(\phi, \theta) = \frac{1}{n} (\mathbf{x^{(i)}} - f_\theta(g_\phi(\tilde{\mathbf{x}})))^2
$$<p><img alt="Figure 2: An illustration of the latent space for " loading=lazy src=/images/autoencoder/dae.png></p><h2 id=sparse-autoencoders>Sparse Autoencoders<a hidden class=anchor aria-hidden=true href=#sparse-autoencoders>#</a></h2><p>A <strong>Sparse Autoencoder</strong><a href=https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf>[3]</a> (SAE) introduces a sparsity constraint on the hidden layer to enforce the model to learn meaningful features of the data. The sparsity constraint ensures that only a small number of neurons are &ldquo;active&rdquo; (have high activation values) for any given input, which promotes feature selection and boosts robustness.</p><h3 id=why-sparsity>Why Sparsity?<a hidden class=anchor aria-hidden=true href=#why-sparsity>#</a></h3><p>The sparsity constraint makes the autoencoder focus on capturing essential features of the data, rather than just memorizing input-output mappings. This is especially useful when:</p><ul><li>The input data has high dimensionality (e.g. images).</li><li>We want to learn interpretable features.</li><li>The dataset is noisy, and only certain features are relevant.</li></ul><p>Sparsity is typically enforced by adding a <strong>regularization term</strong> to the loss function. A common choice is the Kullback-Leibler (KL) divergence, which measures the difference between:</p><ul><li>The average activation of a neuron $ \hat{\rho}_j $, and</li><li>A target sparsity value $ \rho$ (e.g., $\rho = 0.05 $).</li></ul>$$
\text{Sparsity Penalty} = \sum_{j=1}^m \text{KL}(\rho || \hat{\rho}_j)
$$$$
= \sum_{j=1}^m [ \rho \log \frac{\rho}{\hat{\rho}_j} + (1 - \rho) \log \frac{1 - \rho}{1 - \hat{\rho}_j}]
$$<p>where:</p><ul><li>$\hat{\rho}_j$: The average activation of the $j$-th hidden neuron across the dataset.</li><li>$m$: The number of hidden neurons.</li></ul>$$
L = L_\text{reconstruction} + \beta \cdot \text{Sparsity Penalty},
$$<p>where $\beta$ is a hyperparameter controlling the importance of sparsity.</p><h3 id=k-sparse-autoencoders>K-Sparse Autoencoders<a hidden class=anchor aria-hidden=true href=#k-sparse-autoencoders>#</a></h3><p>A <strong>K-Sparse Autoencoder</strong><a href=https://arxiv.org/abs/1312.5663>[4]</a> is a specific type of sparse autoencoder where exactly $k$ neurons in the hidden layer are allowed to be &ldquo;active&rdquo; for any given input. This enforces a strict sparsity constraint, where only the top $k$ activations (largest values) are retained, and the rest are set to zero.</p><h3 id=how-k-sparsity-works>How K-Sparsity Works<a hidden class=anchor aria-hidden=true href=#how-k-sparsity-works>#</a></h3><ol><li>For each input $\mathbf{x} $:<ul><li>Compute the activations of the hidden layer.</li><li>Retain the top $k $ activations (by magnitude) and set all others to zero.</li></ul></li><li>During backpropagation, only the selected $k$ -active neurons contribute to the gradient update.</li></ol><p>This approach has the following properties:</p><ul><li>It ensures a fixed level of sparsity ($k $-out-of-$ m $ neurons active).</li><li>It does not require additional sparsity penalties in the loss function, as the sparsity is explicitly enforced.</li></ul><h2 id=variational-autoencoders>Variational Autoencoders<a hidden class=anchor aria-hidden=true href=#variational-autoencoders>#</a></h2><p>One major limitation of standard autoencoders is that their latent space often lacks meaningful structure. When sampling random points from the latent space, the decoder may produce nonsensical or meaningless outputs. This happens because the decoder is not explicitly trained to map random points in the latent space back to realistic data.</p><p><img alt="Figure 2: An illustration of the latent space for " loading=lazy src=/images/autoencoder/example-ae3.png></p><p>To address this issue, the authors of the paper <a href=https://arxiv.org/abs/1312.6114>[5]</a> take a different approach. Instead of learning fixed features for a data point, VAEs aim to learn the <strong>distribution</strong> of the dataset $D$, which we denote as $p_*(\mathbf{x})$.</p><p>For the example before, with VAEs, when sampling random points from the latent space we get a morph of mammals i.e a point between human and jaguar will produce an image of the combined.</p><h3 id=explanation-1>Explanation<a hidden class=anchor aria-hidden=true href=#explanation-1>#</a></h3><p>The goal of the VAEs is to generate unseen data by learning a distribution $p_\theta(\mathbf{x})$ that approximates the true distribution $p_*(\mathbf{x})$:</p>$$
p_\theta(\mathbf{x}) \approx p_*(\mathbf{x}).
$$<p>To achieve this, we maximize the likelihood of the model&rsquo;s distribution $p_\theta(\mathbf{x})$. Specifically, the objective is to find the parameters $ \theta$ that maximize the likelihood of the observed data:</p>$$
\theta^* = \arg\max_\theta \prod_{i=1}^n p_\theta(\mathbf{x}^{(i)}).
$$$$
\theta^* = \arg\max_\theta \sum_{i=1}^n \log p_\theta(\mathbf{x}^{(i)}).
$$$$
p_\theta(\mathbf{x}) = \int_\mathbf{z} p_\theta(\mathbf{x} \vert \mathbf{z}) p_\theta(\mathbf{z}) d\mathbf{z}.
$$<h3 id=the-challenge-intractability>The Challenge: Intractability<a hidden class=anchor aria-hidden=true href=#the-challenge-intractability>#</a></h3><p>The problem with directly evaluating this integral is that it is computationally infeasible. Marginalizing over $\mathbf{z}$ requires summing over all possible values of $\mathbf{z}$, which is not practical due to the high dimensionality of the latent space.</p><h3 id=the-solution-variational-approximation>The Solution: Variational Approximation<a hidden class=anchor aria-hidden=true href=#the-solution-variational-approximation>#</a></h3><p>To approximate this integral, VAEs introduce a <strong>variational distribution</strong> $q_\phi(\mathbf{z} \vert \mathbf{x}) $ as a surrogate for the intractable posterior $ p_\theta(\mathbf{z} \vert \mathbf{x}) $. This approximation enables efficient optimization using the <strong>Evidence Lower Bound (ELBO)</strong>, which we will explore in detail next.</p><hr><h4 id=rem-bayes-theorem>REM: Bayes Theorem<a hidden class=anchor aria-hidden=true href=#rem-bayes-theorem>#</a></h4>$$
P(H|E) = \frac{P(H) \space P(E|H)} {P(E)}
$$<p>where;</p><p>$P(H|E)$ - The posterior probability. The probability of getting the hypothesis $H$ given we have observed an event $E$.</p><p>$P(H)$ - The prior probability. The probability of getting the hypothesis without the evidence.</p><p>$P(E|H)$ - The likelihood/ the update. The probability of observing an event given we have formulated a hypothesis.</p><p>$P(E)$ - The marginal likelihood/model evidence. The probability of just observing the event without the hypothesis. <em>Normalizer</em></p><hr><h4 id=variational-inference>Variational Inference<a hidden class=anchor aria-hidden=true href=#variational-inference>#</a></h4>$$
p_\theta(\mathbf{z|x}) = \frac{p_\theta(\mathbf{z}) \space p_\theta(\mathbf{x|z})} {p_\theta(\mathbf{x})}
$$<p>We would like to maximize $p_\theta(\mathbf{x})$(which is intractable) but since $p_\theta(\mathbf{x}) = \frac{p_\theta(\mathbf{z,x})}{p_\theta(\mathbf{z|x})}$ getting $p_\theta(\mathbf{z|x})$ would also be computationally expensive as the probability depends on knowledge on $p_\theta(\mathbf{x})$</p>$$
q_\phi(\mathbf{z|x}) \approx p_\theta(\mathbf{z|x})
$$<p>where; $q_\phi(\mathbf{z|x})$ is the approximation and $p_\theta(\mathbf{z|x})$ is the target.</p><figure><img src=/images/autoencoder/vae-1.png>
<figurecaption>Figure2: VAE showing the variational inference</figurecaption></figure><p>We minimize the gap between the two distributions by using the <a href=https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence>Kullback-Leibler Divergence</a></p>$$
D_\text{KL}( q_\phi(\mathbf{z}\vert\mathbf{x})\space || \space p_\theta(\mathbf{z}\vert\mathbf{x}) )
$$<p>The above means; the information lost if we adopt the $p_\phi(\mathbf{z|x})$ as our true distribution and $p_\theta(\mathbf{z|x})
$ as the approximation.</p>$$
\begin{aligned}
&\displaystyle D_\text{KL}( q_\phi(\mathbf{z}\vert\mathbf{x}) \| p_\theta(\mathbf{z}\vert\mathbf{x}) ) & \\
&= \int_z q_\phi(\mathbf{z} \vert \mathbf{x}) \log\frac{q_\phi(\mathbf{z} \vert \mathbf{x})}{p_\theta(\mathbf{z} \vert \mathbf{x})} d\mathbf{z} & \\
&= \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}[\log \frac{q_\phi(\mathbf{z} \vert \mathbf{x})}{p_\theta(\mathbf{z} \vert \mathbf{x})}] & \\
&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}
[\log q_\phi(\mathbf{z} \vert \mathbf{x}) - \log p_\theta(\mathbf{z} \vert \mathbf{x})] & \\
&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}
\log q_\phi(\mathbf{z} \vert \mathbf{x}) - \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log p_\theta(\mathbf{z} \vert \mathbf{x}) & \\
&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}
\log q_\phi(\mathbf{z} \vert \mathbf{x}) - \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log [\frac {p_\theta(\mathbf{z}, \mathbf{x})}{p_\theta(\mathbf{x})}] & \scriptstyle{\text{; Because }p(z \vert x) = p(z, x) / p(x)\text{}} \\
&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}
\log q_\phi(\mathbf{z} \vert \mathbf{x}) - \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log p_\theta(\mathbf{z} , \mathbf{x}) + \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log p_\theta(\mathbf{x}) & \\
&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}
\log q_\phi(\mathbf{z} \vert \mathbf{x}) - \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log p_\theta(\mathbf{z} , \mathbf{x}) + \int{q_\phi(\mathbf{z} \vert \mathbf{x})}\log p_\theta(\mathbf{x}) d\mathbf{z} & \\
&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}
\log q_\phi(\mathbf{z} \vert \mathbf{x}) - \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log p_\theta(\mathbf{z} , \mathbf{x}) + \log p_\theta(\mathbf{x}) & \scriptstyle {\text{; Because }\int q(z \vert x) dz = 1} \\
&=\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}
[\log q_\phi(\mathbf{z} \vert \mathbf{x}) - \log p_\theta(\mathbf{z} , \mathbf{x})] + \log p_\theta(\mathbf{x}) & \\
&=\log p_\theta(\mathbf{x}) + \int_z q_\phi(\mathbf{z} \vert \mathbf{x})\log\frac{q_\phi(\mathbf{z} \vert \mathbf{x})}{p_\theta(\mathbf{z}, \mathbf{x})} d\mathbf{z} & \\
&=\log p_\theta(\mathbf{x}) + \int_z q_\phi(\mathbf{z} \vert \mathbf{x})\log\frac{q_\phi(\mathbf{z} \vert \mathbf{x})}{p_\theta(\mathbf{x}\vert\mathbf{z})p_\theta(\mathbf{z})} d\mathbf{z} &\scriptstyle{\text{; Because }p(z, x) = p(x \vert z) p(z)} \\
&=\log p_\theta(\mathbf{x}) + \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}[\log \frac{q_\phi(\mathbf{z} \vert \mathbf{x})}{p_\theta(\mathbf{z})} - \log p_\theta(\mathbf{x} \vert \mathbf{z})] & \\
&=\log p_\theta(\mathbf{x}) + D_\text{KL}(q_\phi(\mathbf{z}\vert\mathbf{x}) \| p_\theta(\mathbf{z})) - \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}\vert\mathbf{x})}\log p_\theta(\mathbf{x}\vert\mathbf{z}) &
\end{aligned}
$$<p>Another way to derive it is using the <a href=https://en.wikipedia.org/wiki/Jensen%27s_inequality>Jensen&rsquo;s Inequality</a></p><p>If we rearrange the equation, we should get</p>$$
\log p_\theta(\mathbf{x}) - D_\text{KL}( q_\phi(\mathbf{z}\vert\mathbf{x}) \| p_\theta(\mathbf{z}\vert\mathbf{x}) ) = \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}\vert\mathbf{x})}\log p_\theta(\mathbf{x}\vert\mathbf{z}) - D_\text{KL}(q_\phi(\mathbf{z}\vert\mathbf{x}) \| p_\theta(\mathbf{z}))
$$<p>On the LHS, we have the log likelihood which we would wish to maximize or to say minimize the negative log likelihood. The KL Divergence acts as a regularizer.
Since the KL Divergence is always positive, the RHS is the lower bound of the $\log p_\theta(\mathbf{x})$</p>$$
\text{ELBO} = -\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log\frac { q_\phi(\mathbf{z} \vert \mathbf{x})}{ p_\theta(\mathbf{z} , \mathbf{x})}
$$$$
\text{ELBO} = \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log\frac { p_\theta(\mathbf{z} , \mathbf{x})}{ q_\phi(\mathbf{z} \vert \mathbf{x})}
$$$$
\text{ELBO} = \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z}\vert\mathbf{x})}\log p_\theta(\mathbf{x}\vert\mathbf{z}) - D_\text{KL}(q_\phi(\mathbf{z}\vert\mathbf{x}) \| p_\theta(\mathbf{z}))
$$<p>The loss function is the negative log likelihood:</p>$$
\begin{aligned}
&L_(\theta, \phi) \\
&=-\log p_\theta(\mathbf{x}) + D_\text{KL}( q_\phi(\mathbf{z}\vert\mathbf{x}) \| p_\theta(\mathbf{z}\vert\mathbf{x}) ) \\
&=-\mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}\vert\mathbf{x})} \log p_\theta(\mathbf{x}\vert\mathbf{z}) + D_\text{KL}( q_\phi(\mathbf{z}\vert\mathbf{x}) \| p_\theta(\mathbf{z}) ) \\
&\theta^{*}, \phi^{*} = \arg\min_{\theta, \phi} L
\end{aligned}
$$$$
\nabla_{\theta,\phi} {L} = \nabla_\theta [- \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log\frac { q_\phi(\mathbf{z} \vert \mathbf{x})}{ p_\theta(\mathbf{z} , \mathbf{x})}]
$$<p>They solved this using the <a href=https://en.wikipedia.org/wiki/Reparameterization_trick>reparameterization trick</a>.</p><h4 id=reparameterization-trick>Reparameterization Trick<a hidden class=anchor aria-hidden=true href=#reparameterization-trick>#</a></h4><p>Lets try backproping from the loss w.r.t $\theta$</p>$$
L(\theta, \phi) = - \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log\frac { q_\phi(\mathbf{z} \vert \mathbf{x})}{ p_\theta(\mathbf{z} , \mathbf{x})}
$$$$
\begin{aligned}
&\nabla_\theta {L} = \nabla_\theta [- \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log\frac { q_\phi(\mathbf{z} \vert \mathbf{x})}{ p_\theta(\mathbf{z} , \mathbf{x})}] \\
&= \nabla_\theta [\mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log\frac { p_\theta(\mathbf{z} , \mathbf{x})}{ q_\phi(\mathbf{z} \vert \mathbf{x})}] \\
&= \nabla_\theta(\int_z q_\phi(\mathbf{z} \vert \mathbf{x})[\log\ p_\theta(\mathbf{z} , \mathbf{x}) - \log q_\phi(\mathbf{z} \vert \mathbf{x})]d\mathbf{z}) \\
&= \int_z q_\phi(\mathbf{z} \vert \mathbf{x})\nabla_\theta[\log\ p_\theta(\mathbf{z} , \mathbf{x}) - \log q_\phi(\mathbf{z} \vert \mathbf{x})]d\mathbf{z} \\
&= \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\nabla_\theta[\log\ p_\theta(\mathbf{z} , \mathbf{x}) - \log q_\phi(\mathbf{z} \vert \mathbf{x})] \\
&= \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\nabla_\theta[\log\ p_\theta(\mathbf{z} , \mathbf{x}) ]
\end{aligned}
$$<p>We can see that the gradient of the expectation is just the expectation of the gradient. We can easily estimate the expectation using Naïve Monte-Carlo sampling.</p>$$
\nabla_\theta {L} \approx \frac {1}{n} \sum_{i=1} ^n \nabla_\theta[\log\ p_\theta(\mathbf{z} , \mathbf{x}) ]
$$<p>The problem now is the gradient w.r.t $\phi$</p>$$
\begin{aligned}
&\nabla_\phi {L} = \nabla_\phi [- \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})}\log\frac { q_\phi(\mathbf{z} \vert \mathbf{x})}{ p_\theta(\mathbf{z} , \mathbf{x})}] \\
&= \nabla_\phi (\int_z q_\phi(\mathbf{z} \vert \mathbf{x})[\log\ p_\theta(\mathbf{z} , \mathbf{x}) - q_\phi(\mathbf{z} \vert \mathbf{x})]d\mathbf{z}) \\
&= \int_z \nabla_\phi [q_\phi(\mathbf{z} \vert \mathbf{x}) \cdot\text{ELBO}]d\mathbf{z} \\
&= \int_z q_\phi(\mathbf{z} \vert \mathbf{x}) \cdot \nabla_\phi \text{ELBO} d\mathbf{z} + \int_z \text{ELBO} \cdot \nabla_\phi q_\phi(\mathbf{z} \vert \mathbf{x})d\mathbf{z} \\
&= \mathbb{E}_{\mathbf{z}\sim q_\phi(\mathbf{z} \vert \mathbf{x})} \cdot \nabla_\phi \text{ELBO} + \int_z \text{ELBO} \cdot \nabla_\phi q_\phi(\mathbf{z} \vert \mathbf{x})d\mathbf{z}
\end{aligned}
$$<p>You can notice that the first term can be estimated as it is an expectation. However, the second expression is not an expectation and therefore cannot be calculated because we do not have the gradient of $q_\phi$. The solution is to replace $q$ with an equivalent distribution that is not parameterized by $\phi$. This is the reparameterization trick.</p>$$
\begin{aligned}
\mathbf{z} &\sim q_\phi(\mathbf{z}\vert\mathbf{x}^{(i)}) = \mathcal{N}(\mathbf{z}; \boldsymbol{\mu}^{(i)}, \boldsymbol{\sigma}^{2(i)}\boldsymbol{I}) \\
\mathbf{z} &= \boldsymbol{\mu} + \boldsymbol{\sigma} \odot \boldsymbol{\epsilon} \text{, where } \boldsymbol{\epsilon} \sim \mathcal{N}(0, \boldsymbol{I})
\end{aligned}
$$<p>This essentially tranfers the randomness from $\mathbf{z}$ to an external variable $\boldsymbol{\epsilon}$</p><p><img alt="Figure3: The reparameterization trick" loading=lazy src=/images/autoencoder/reparameterization.png></p><h5 id=gradient-wrt--phi-with-reparameterization>Gradient w.r.t. $ \phi$ with reparameterization.<a hidden class=anchor aria-hidden=true href=#gradient-wrt--phi-with-reparameterization>#</a></h5><p>Using the reparameterization trick, we rewrite $\mathbf{z}$ as:</p>$$
\mathbf{z} = \boldsymbol{\mu}_\phi(\mathbf{x}) + \boldsymbol{\sigma}_\phi(\mathbf{x}) \odot \boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I}).
$$$$
\text{ELBO}(\phi, \theta) = \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \log \frac{p_\theta(\mathbf{z}, \mathbf{x})} {q_\phi(\mathbf{z} \vert \mathbf{x})}
$$<p>The gradient w.r.t. $ \phi$ is:</p>$$
\nabla_\phi L = - \nabla_\phi \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \log \frac{p_\theta(\mathbf{z}, \mathbf{x})} {q_\phi(\mathbf{z} \vert \mathbf{x})}
$$$$
\nabla_\phi L = - \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})} \left[ \nabla_\phi \log p_\theta(\mathbf{z}, \mathbf{x}) - \nabla_\phi \log q_\phi(\mathbf{z} \vert \mathbf{x}) \right].
$$<h3 id=breaking-down-the-gradients>Breaking Down the Gradients:<a hidden class=anchor aria-hidden=true href=#breaking-down-the-gradients>#</a></h3><ol><li><p><strong>Gradient of $\log p_\theta(\mathbf{z}, \mathbf{x}) $:</strong>
Since $\mathbf{z}$ depends on $\phi $ through $\boldsymbol{\mu}_\phi$ and $\boldsymbol{\sigma}_\phi $, the gradient propagates as:</p>$$
\nabla_\phi \log p_\theta(\mathbf{z}, \mathbf{x}) = \nabla_\mathbf{z} \log p_\theta(\mathbf{z}, \mathbf{x}) \cdot \nabla_\phi \mathbf{z}.
$$</li><li><p><strong>Gradient of $\log q_\phi(\mathbf{z} \vert \mathbf{x})$:</strong>
For a Gaussian distribution $q_\phi(\mathbf{z} \vert \mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}_\phi, \boldsymbol{\sigma}_\phi^2 \mathbf{I})$, the log-probability is:</p>$$
\log q_\phi(\mathbf{z} \vert \mathbf{x}) = -\frac{1}{2} \left[ \log (2\pi) + \log (\boldsymbol{\sigma}_\phi^2) + \frac{(\mathbf{z} - \boldsymbol{\mu}_\phi)^2}{\boldsymbol{\sigma}_\phi^2} \right].
$$<p>Its gradient w.r.t. $\phi$ is:</p>$$
\nabla_\phi \log q_\phi(\mathbf{z} \vert \mathbf{x}) = \nabla_\phi \left( \frac{\mathbf{z} - \boldsymbol{\mu}_\phi}{\boldsymbol{\sigma}_\phi^2} \cdot (\mathbf{z} - \boldsymbol{\mu}_\phi) - \log \boldsymbol{\sigma}_\phi \right).
$$</li></ol><h5 id=gradient-wrt-theta>Gradient w.r.t. $\theta$<a hidden class=anchor aria-hidden=true href=#gradient-wrt-theta>#</a></h5><p>As derived earlier, the gradient w.r.t. $\theta$ is simpler:</p>$$
\nabla_\theta L = \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z} \vert \mathbf{x})} \nabla_\theta \log p_\theta(\mathbf{z}, \mathbf{x})
$$<p>Using Monte Carlo sampling, this is approximated as:</p>$$
\nabla_\theta L \approx \frac{1}{n} \sum_{i=1}^n \nabla_\theta \log p_\theta(\mathbf{z}^{(i)}, \mathbf{x})
$$<figure><img src=/images/autoencoder/vae-2.png>
<figurecaption></figurecaption></figure><hr><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><ol><li>Geoffrey E. Hinton, and Ruslan R. Salakhutdinov. <a href=https://pdfs.semanticscholar.org/c50d/ca78e97e335d362d6b991ae0e1448914e9a3.pdf>Reducing the dimensionality of data with neural networks</a> (2006).</li><li>Pascal Vincent, et al. <a href=http://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf>Extracting and composing robust features with denoising autoencoders</a> (2008)</li><li>Andrew Ng. <a href=https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf>Sparse Autoencoder</a></li><li>Alireza Makhzani, Brendan Frey (2013). <a href=https://arxiv.org/abs/1312.5663>k-sparse autoencoder</a> (2014).</li><li>Diederik P. Kingma, and Max Welling. <a href=https://arxiv.org/abs/1312.6114>Auto-encoding variational bayes</a> (2014).</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://mwauracollins.github.io/tags/autoencoders/>Autoencoders</a></li><li><a href=https://mwauracollins.github.io/tags/deep-learning/>Deep-Learning</a></li><li><a href=https://mwauracollins.github.io/tags/generative-models/>Generative-Models</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Autoencoders on x" href="https://x.com/intent/tweet/?text=Autoencoders&amp;url=https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f&amp;hashtags=autoencoders%2cdeep-learning%2cgenerative-models"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Autoencoders on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f&amp;title=Autoencoders&amp;summary=Autoencoders&amp;source=https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Autoencoders on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f&title=Autoencoders"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Autoencoders on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Autoencoders on whatsapp" href="https://api.whatsapp.com/send?text=Autoencoders%20-%20https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Autoencoders on telegram" href="https://telegram.me/share/url?text=Autoencoders&amp;url=https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Autoencoders on ycombinator" href="https://news.ycombinator.com/submitlink?t=Autoencoders&u=https%3a%2f%2fmwauracollins.github.io%2fposts%2f2025-01-16-autoencoders%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://mwauracollins.github.io/>mwaura.AI</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>