<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on mwaura.AI</title>
    <link>https://mwauracollins.github.io/posts/</link>
    <description>Recent content in Posts on mwaura.AI</description>
    <generator>Hugo -- 0.145.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 23 Feb 2025 22:30:36 +0300</lastBuildDate>
    <atom:link href="https://mwauracollins.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Reinforcement Learning (Part 1): Bandits </title>
      <link>https://mwauracollins.github.io/posts/2025-02-23-rl_bandits/</link>
      <pubDate>Sun, 23 Feb 2025 22:30:36 +0300</pubDate>
      <guid>https://mwauracollins.github.io/posts/2025-02-23-rl_bandits/</guid>
      <description>From Bandits to GRPO</description>
    </item>
    <item>
      <title>Rolling Your Own GPT</title>
      <link>https://mwauracollins.github.io/posts/2025-02-04-gpt/</link>
      <pubDate>Tue, 04 Feb 2025 22:20:47 +0300</pubDate>
      <guid>https://mwauracollins.github.io/posts/2025-02-04-gpt/</guid>
      <description>&lt;p&gt;Training a GPT model sounds like a moonshot but it is actually just a series of simple and well-defined steps.
At its core, it is just a giant text predictor, fed with tons of data and then allowed to guess the next word. The real challenge is not training it to predict the next word, but to make it produce something useful like answers to your assignment due midnight.ðŸ˜…
You need some special type of training like &lt;strong&gt;Reinforcement Learning with Human Feedback &lt;a href=&#34;#rlhf&#34;&gt;(RLHF)&lt;/a&gt;&lt;/strong&gt;. Though you can get good responses without RLHF, RLHF is required to make it chatbot-like.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unraveling RoPE: Encoding Relative Positions in Transformers with Elegance</title>
      <link>https://mwauracollins.github.io/posts/2025-01-24-rope/</link>
      <pubDate>Fri, 24 Jan 2025 12:15:11 +0300</pubDate>
      <guid>https://mwauracollins.github.io/posts/2025-01-24-rope/</guid>
      <description>&lt;h2 id=&#34;why-positional-encoding&#34;&gt;Why Positional Encoding?&lt;/h2&gt;
&lt;p&gt;Unlike recurrent neural networks (RNNs), transformers process tokens in parallel meaning they do not inherently understand the order of words in a sequence. In language, the meaning of a word can heavily depend on its position, for example, &lt;em&gt;&amp;ldquo;Salt has important minerals.&amp;rdquo;&lt;/em&gt; and &lt;em&gt;&amp;ldquo;The food is so bland I had to salt it.&amp;rdquo;&lt;/em&gt;. Salt is used as a noun and verb depending on it position on the sentence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Optimizers</title>
      <link>https://mwauracollins.github.io/posts/2025-01-21-optimizers/</link>
      <pubDate>Tue, 21 Jan 2025 12:34:55 +0300</pubDate>
      <guid>https://mwauracollins.github.io/posts/2025-01-21-optimizers/</guid>
      <description>Diving into what makes AI &amp;#39;smart&amp;#39;. </description>
    </item>
    <item>
      <title>Autoencoders</title>
      <link>https://mwauracollins.github.io/posts/2025-01-16-autoencoders/</link>
      <pubDate>Wed, 15 Jan 2025 21:23:02 +0300</pubDate>
      <guid>https://mwauracollins.github.io/posts/2025-01-16-autoencoders/</guid>
      <description>An overview of autoencoders with a simplified explanation.</description>
    </item>
  </channel>
</rss>
